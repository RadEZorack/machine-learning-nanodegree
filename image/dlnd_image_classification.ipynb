{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [04:39, 611KB/s]                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27ec541c7f0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x/255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(10)[x]\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=(None, image_shape[0], image_shape[1], image_shape[2]), name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=(None, n_classes), name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    color_channels = x_tensor.get_shape().as_list()[3]\n",
    "    weight = tf.Variable(tf.truncated_normal([conv_ksize[0],conv_ksize[1],color_channels,conv_num_outputs]))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weight, strides=[1,conv_strides[0],conv_strides[1],1], padding='SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    pool = tf.nn.max_pool(conv_layer, [1,pool_ksize[0],pool_ksize[1],1], [1,pool_strides[0],pool_strides[1],1], padding='SAME')\n",
    "    return pool \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    return tf.reshape(x_tensor,[-1,dimension[1]*dimension[2]*dimension[3]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    shape = [dimension[1], num_outputs]\n",
    "    \n",
    "    weight = tf.Variable(tf.truncated_normal(shape,0,0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    return tf.nn.relu(tf.add(tf.matmul(x_tensor,weight), bias))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    shape = [dimension[1], num_outputs]\n",
    "    \n",
    "    weight = tf.Variable(tf.truncated_normal(shape,0,0.01))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    return tf.add(tf.matmul(x_tensor,weight), bias)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    model = conv2d_maxpool(x, conv_num_outputs=18, conv_ksize=(4,4), conv_strides=(1,1), pool_ksize=(8,8), pool_strides=(1,1))\n",
    "\n",
    "    model = tf.nn.dropout(model, keep_prob)\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    model = flatten(model)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    model = fully_conn(model,384)\n",
    "    \n",
    "    model = tf.nn.dropout(model, keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    model = output(model,10)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: valid_features,\n",
    "                y: valid_labels,\n",
    "                keep_prob: 1.})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                loss,\n",
    "                valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3019 Validation Accuracy: 0.097800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.2897 Validation Accuracy: 0.110600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.2693 Validation Accuracy: 0.122600\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.2686 Validation Accuracy: 0.112800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.2526 Validation Accuracy: 0.193800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.1998 Validation Accuracy: 0.226400\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.1818 Validation Accuracy: 0.225000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.1457 Validation Accuracy: 0.223800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.1422 Validation Accuracy: 0.232600\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.1050 Validation Accuracy: 0.217800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.0821 Validation Accuracy: 0.236400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     2.0910 Validation Accuracy: 0.249400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     2.0702 Validation Accuracy: 0.266000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     2.0184 Validation Accuracy: 0.270000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.9916 Validation Accuracy: 0.265400\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     2.0006 Validation Accuracy: 0.291600\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.9417 Validation Accuracy: 0.292800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.9584 Validation Accuracy: 0.293000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.9437 Validation Accuracy: 0.291800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.9161 Validation Accuracy: 0.301000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.8871 Validation Accuracy: 0.319600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.8807 Validation Accuracy: 0.294000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.8788 Validation Accuracy: 0.323600\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.8594 Validation Accuracy: 0.319000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.8530 Validation Accuracy: 0.338200\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.8375 Validation Accuracy: 0.325200\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.8149 Validation Accuracy: 0.327800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.7915 Validation Accuracy: 0.343200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.8014 Validation Accuracy: 0.348000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.7791 Validation Accuracy: 0.327400\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.7587 Validation Accuracy: 0.330400\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.7561 Validation Accuracy: 0.364800\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.7286 Validation Accuracy: 0.380600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.7356 Validation Accuracy: 0.361000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.7362 Validation Accuracy: 0.336800\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.7127 Validation Accuracy: 0.368800\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.7090 Validation Accuracy: 0.360800\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.6761 Validation Accuracy: 0.370200\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.6585 Validation Accuracy: 0.383000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.6667 Validation Accuracy: 0.367000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.6548 Validation Accuracy: 0.377600\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.6554 Validation Accuracy: 0.397600\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.6433 Validation Accuracy: 0.395200\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.6381 Validation Accuracy: 0.390800\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.6182 Validation Accuracy: 0.397200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.6077 Validation Accuracy: 0.394600\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.5931 Validation Accuracy: 0.407000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.5925 Validation Accuracy: 0.402400\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.5934 Validation Accuracy: 0.415800\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.6035 Validation Accuracy: 0.414800\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.5934 Validation Accuracy: 0.409400\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.5783 Validation Accuracy: 0.407400\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.5878 Validation Accuracy: 0.427600\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.5835 Validation Accuracy: 0.407200\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.5645 Validation Accuracy: 0.431400\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.5535 Validation Accuracy: 0.415200\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.5410 Validation Accuracy: 0.416400\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.5593 Validation Accuracy: 0.422800\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.5359 Validation Accuracy: 0.415200\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.5189 Validation Accuracy: 0.428800\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.5335 Validation Accuracy: 0.440600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.5211 Validation Accuracy: 0.426600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.5125 Validation Accuracy: 0.446600\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.5121 Validation Accuracy: 0.430000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.5155 Validation Accuracy: 0.443000\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.5019 Validation Accuracy: 0.456400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.4911 Validation Accuracy: 0.445200\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.4643 Validation Accuracy: 0.461200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.4768 Validation Accuracy: 0.455600\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.4508 Validation Accuracy: 0.449800\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.4579 Validation Accuracy: 0.467000\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.4733 Validation Accuracy: 0.456800\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.4211 Validation Accuracy: 0.472200\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.4052 Validation Accuracy: 0.463000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.4242 Validation Accuracy: 0.460800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.4103 Validation Accuracy: 0.472200\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.4004 Validation Accuracy: 0.468000\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.3918 Validation Accuracy: 0.479400\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.3873 Validation Accuracy: 0.469600\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.3723 Validation Accuracy: 0.488800\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.3543 Validation Accuracy: 0.483400\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.3655 Validation Accuracy: 0.480000\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.3658 Validation Accuracy: 0.482200\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.3756 Validation Accuracy: 0.482200\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.3646 Validation Accuracy: 0.492400\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.3519 Validation Accuracy: 0.497200\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.3307 Validation Accuracy: 0.492600\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.3184 Validation Accuracy: 0.501600\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.2841 Validation Accuracy: 0.507200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.3090 Validation Accuracy: 0.484600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.3114 Validation Accuracy: 0.496600\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.2888 Validation Accuracy: 0.500600\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.2907 Validation Accuracy: 0.494000\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.2772 Validation Accuracy: 0.505000\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.2640 Validation Accuracy: 0.506400\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.2406 Validation Accuracy: 0.501600\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.2762 Validation Accuracy: 0.507000\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.2705 Validation Accuracy: 0.504000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.2437 Validation Accuracy: 0.500000\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.2233 Validation Accuracy: 0.505800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3027 Validation Accuracy: 0.101600\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.3027 Validation Accuracy: 0.106800\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.3025 Validation Accuracy: 0.106800\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.3025 Validation Accuracy: 0.094200\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.3026 Validation Accuracy: 0.094200\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.3020 Validation Accuracy: 0.096400\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     2.2687 Validation Accuracy: 0.137600\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     2.2324 Validation Accuracy: 0.168600\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     2.1370 Validation Accuracy: 0.174400\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     2.0919 Validation Accuracy: 0.165800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.1135 Validation Accuracy: 0.205200\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     2.0203 Validation Accuracy: 0.216000\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     2.0655 Validation Accuracy: 0.181400\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     2.0312 Validation Accuracy: 0.192200\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     2.0338 Validation Accuracy: 0.213200\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.0870 Validation Accuracy: 0.201200\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.9882 Validation Accuracy: 0.218000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     2.0355 Validation Accuracy: 0.229400\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.9597 Validation Accuracy: 0.254400\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.9436 Validation Accuracy: 0.238600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.9928 Validation Accuracy: 0.245600\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.8780 Validation Accuracy: 0.264800\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.8839 Validation Accuracy: 0.266200\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.8022 Validation Accuracy: 0.264200\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.8484 Validation Accuracy: 0.281000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.9092 Validation Accuracy: 0.282600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.7599 Validation Accuracy: 0.275200\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.8090 Validation Accuracy: 0.285800\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.7374 Validation Accuracy: 0.298000\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.8198 Validation Accuracy: 0.287800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.8751 Validation Accuracy: 0.271200\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.7779 Validation Accuracy: 0.316200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.7805 Validation Accuracy: 0.301200\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.7093 Validation Accuracy: 0.314200\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.7802 Validation Accuracy: 0.289200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.8373 Validation Accuracy: 0.270600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.7350 Validation Accuracy: 0.281000\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.7049 Validation Accuracy: 0.283000\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.6495 Validation Accuracy: 0.336400\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.7452 Validation Accuracy: 0.336200\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.8200 Validation Accuracy: 0.313400\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.7390 Validation Accuracy: 0.309000\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.6899 Validation Accuracy: 0.335400\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.6516 Validation Accuracy: 0.328400\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.7231 Validation Accuracy: 0.338000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.8078 Validation Accuracy: 0.332000\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.6996 Validation Accuracy: 0.356600\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.6543 Validation Accuracy: 0.354800\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.6168 Validation Accuracy: 0.381200\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.7039 Validation Accuracy: 0.374800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.7498 Validation Accuracy: 0.337200\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.6350 Validation Accuracy: 0.405400\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.5929 Validation Accuracy: 0.366600\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.5748 Validation Accuracy: 0.412600\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.6786 Validation Accuracy: 0.387000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.7465 Validation Accuracy: 0.405600\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.6267 Validation Accuracy: 0.389400\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.5872 Validation Accuracy: 0.407000\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.5667 Validation Accuracy: 0.426600\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.6132 Validation Accuracy: 0.407000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.7040 Validation Accuracy: 0.416600\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.6016 Validation Accuracy: 0.445200\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.4965 Validation Accuracy: 0.421400\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.5559 Validation Accuracy: 0.441400\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.6054 Validation Accuracy: 0.422200\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.6807 Validation Accuracy: 0.432200\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.6000 Validation Accuracy: 0.404400\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.5016 Validation Accuracy: 0.438000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.5109 Validation Accuracy: 0.454600\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.5689 Validation Accuracy: 0.426400\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.6812 Validation Accuracy: 0.430600\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.5834 Validation Accuracy: 0.436400\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.4916 Validation Accuracy: 0.438600\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.4737 Validation Accuracy: 0.450000\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.5633 Validation Accuracy: 0.437200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.6459 Validation Accuracy: 0.439000\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.5569 Validation Accuracy: 0.446000\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.4772 Validation Accuracy: 0.448200\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.4719 Validation Accuracy: 0.442800\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.4956 Validation Accuracy: 0.440200\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.5984 Validation Accuracy: 0.461000\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.5260 Validation Accuracy: 0.454800\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.4309 Validation Accuracy: 0.454400\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.4239 Validation Accuracy: 0.473600\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.4768 Validation Accuracy: 0.450800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.5685 Validation Accuracy: 0.471200\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.4888 Validation Accuracy: 0.474600\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.3967 Validation Accuracy: 0.479000\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.3829 Validation Accuracy: 0.477200\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.4300 Validation Accuracy: 0.461200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.5754 Validation Accuracy: 0.476800\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.4668 Validation Accuracy: 0.465200\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.3837 Validation Accuracy: 0.469800\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.3741 Validation Accuracy: 0.493800\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.4335 Validation Accuracy: 0.470000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.5629 Validation Accuracy: 0.483000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.4407 Validation Accuracy: 0.479600\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.3498 Validation Accuracy: 0.486400\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.3664 Validation Accuracy: 0.491800\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.3985 Validation Accuracy: 0.479400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.5469 Validation Accuracy: 0.482600\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.4394 Validation Accuracy: 0.495400\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.3249 Validation Accuracy: 0.493200\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.3345 Validation Accuracy: 0.491400\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.3979 Validation Accuracy: 0.495600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.4921 Validation Accuracy: 0.487800\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.4225 Validation Accuracy: 0.505800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.3333 Validation Accuracy: 0.494400\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.3421 Validation Accuracy: 0.494200\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.3753 Validation Accuracy: 0.486400\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.5272 Validation Accuracy: 0.472600\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.3933 Validation Accuracy: 0.487000\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.2999 Validation Accuracy: 0.490400\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.3270 Validation Accuracy: 0.494000\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.3472 Validation Accuracy: 0.460600\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.4618 Validation Accuracy: 0.492400\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     1.3791 Validation Accuracy: 0.506800\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.2683 Validation Accuracy: 0.506200\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.2757 Validation Accuracy: 0.508000\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.3015 Validation Accuracy: 0.501600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.4379 Validation Accuracy: 0.522000\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     1.3681 Validation Accuracy: 0.507800\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     1.2921 Validation Accuracy: 0.505200\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.2568 Validation Accuracy: 0.516000\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     1.2739 Validation Accuracy: 0.507000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.4247 Validation Accuracy: 0.500400\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     1.3240 Validation Accuracy: 0.515200\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     1.2319 Validation Accuracy: 0.518800\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     1.2454 Validation Accuracy: 0.513600\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     1.2850 Validation Accuracy: 0.513000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.4034 Validation Accuracy: 0.511000\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     1.3418 Validation Accuracy: 0.509800\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     1.2550 Validation Accuracy: 0.515000\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     1.2714 Validation Accuracy: 0.507200\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     1.2674 Validation Accuracy: 0.518400\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.4056 Validation Accuracy: 0.527800\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     1.3158 Validation Accuracy: 0.500400\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     1.2360 Validation Accuracy: 0.511000\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     1.2485 Validation Accuracy: 0.517400\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     1.2529 Validation Accuracy: 0.521400\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.3907 Validation Accuracy: 0.514200\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     1.3053 Validation Accuracy: 0.523800\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     1.2467 Validation Accuracy: 0.521200\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     1.2352 Validation Accuracy: 0.523400\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     1.2580 Validation Accuracy: 0.523600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.3752 Validation Accuracy: 0.512600\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     1.2940 Validation Accuracy: 0.528600\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     1.2284 Validation Accuracy: 0.523000\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     1.2415 Validation Accuracy: 0.531400\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     1.2499 Validation Accuracy: 0.524400\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.3703 Validation Accuracy: 0.525800\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     1.2871 Validation Accuracy: 0.530800\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     1.2293 Validation Accuracy: 0.526000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     1.2004 Validation Accuracy: 0.520400\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     1.2153 Validation Accuracy: 0.531200\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.3662 Validation Accuracy: 0.524200\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     1.2654 Validation Accuracy: 0.533400\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     1.2127 Validation Accuracy: 0.534200\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     1.2360 Validation Accuracy: 0.522000\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     1.2056 Validation Accuracy: 0.539400\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.3215 Validation Accuracy: 0.532600\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     1.2478 Validation Accuracy: 0.533600\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     1.2099 Validation Accuracy: 0.516800\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     1.1867 Validation Accuracy: 0.531000\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     1.2024 Validation Accuracy: 0.535200\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.3447 Validation Accuracy: 0.531000\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     1.2500 Validation Accuracy: 0.533000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     1.1999 Validation Accuracy: 0.535200\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     1.1595 Validation Accuracy: 0.536800\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     1.2155 Validation Accuracy: 0.542200\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.3506 Validation Accuracy: 0.531000\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     1.2637 Validation Accuracy: 0.537400\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     1.1810 Validation Accuracy: 0.542400\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     1.1750 Validation Accuracy: 0.536600\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     1.2098 Validation Accuracy: 0.549000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.3232 Validation Accuracy: 0.538400\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     1.2210 Validation Accuracy: 0.542800\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     1.1764 Validation Accuracy: 0.538200\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     1.2013 Validation Accuracy: 0.533400\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     1.1939 Validation Accuracy: 0.527800\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.3178 Validation Accuracy: 0.546200\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     1.2019 Validation Accuracy: 0.543000\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     1.1637 Validation Accuracy: 0.540000\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     1.1513 Validation Accuracy: 0.542400\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     1.1675 Validation Accuracy: 0.549000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.2964 Validation Accuracy: 0.546800\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     1.2039 Validation Accuracy: 0.539600\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     1.1600 Validation Accuracy: 0.553000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     1.1623 Validation Accuracy: 0.550000\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     1.1659 Validation Accuracy: 0.541000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.2993 Validation Accuracy: 0.550000\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     1.2063 Validation Accuracy: 0.543800\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     1.1104 Validation Accuracy: 0.547200\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     1.1370 Validation Accuracy: 0.546800\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     1.1457 Validation Accuracy: 0.540800\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.2850 Validation Accuracy: 0.553000\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     1.1900 Validation Accuracy: 0.548400\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     1.1337 Validation Accuracy: 0.552000\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     1.1518 Validation Accuracy: 0.539000\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     1.1874 Validation Accuracy: 0.531400\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.2866 Validation Accuracy: 0.558800\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     1.1823 Validation Accuracy: 0.557400\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     1.1121 Validation Accuracy: 0.555400\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     1.1174 Validation Accuracy: 0.552200\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     1.1384 Validation Accuracy: 0.553400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.2438 Validation Accuracy: 0.566400\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     1.1847 Validation Accuracy: 0.560200\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     1.1385 Validation Accuracy: 0.553400\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     1.1191 Validation Accuracy: 0.557400\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     1.1356 Validation Accuracy: 0.553000\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.2597 Validation Accuracy: 0.560600\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     1.1634 Validation Accuracy: 0.553800\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     1.0990 Validation Accuracy: 0.563800\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     1.1328 Validation Accuracy: 0.558800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     1.1499 Validation Accuracy: 0.548200\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.2282 Validation Accuracy: 0.568400\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     1.1612 Validation Accuracy: 0.559800\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     1.0718 Validation Accuracy: 0.571200\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     1.0824 Validation Accuracy: 0.569800\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     1.1033 Validation Accuracy: 0.561600\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.2420 Validation Accuracy: 0.569000\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     1.1470 Validation Accuracy: 0.566200\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     1.0983 Validation Accuracy: 0.568000\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     1.1002 Validation Accuracy: 0.562000\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     1.1128 Validation Accuracy: 0.562200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.2166 Validation Accuracy: 0.571200\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     1.1430 Validation Accuracy: 0.568800\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     1.0709 Validation Accuracy: 0.575000\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     1.0773 Validation Accuracy: 0.562400\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     1.0832 Validation Accuracy: 0.567800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.2085 Validation Accuracy: 0.570200\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     1.1367 Validation Accuracy: 0.564200\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     1.0628 Validation Accuracy: 0.568000\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     1.0661 Validation Accuracy: 0.568000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     1.0811 Validation Accuracy: 0.572600\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.2082 Validation Accuracy: 0.567800\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     1.1061 Validation Accuracy: 0.579800\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     1.0861 Validation Accuracy: 0.559400\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     1.0428 Validation Accuracy: 0.573000\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     1.0694 Validation Accuracy: 0.572600\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.1806 Validation Accuracy: 0.579000\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     1.0943 Validation Accuracy: 0.572800\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     1.0877 Validation Accuracy: 0.563400\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     1.0652 Validation Accuracy: 0.573200\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     1.0866 Validation Accuracy: 0.549800\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.1752 Validation Accuracy: 0.575600\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     1.1035 Validation Accuracy: 0.574000\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     1.0289 Validation Accuracy: 0.582200\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     1.0483 Validation Accuracy: 0.575800\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     1.0677 Validation Accuracy: 0.572400\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.1669 Validation Accuracy: 0.584200\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     1.1127 Validation Accuracy: 0.579400\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     1.0230 Validation Accuracy: 0.573000\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     1.0386 Validation Accuracy: 0.569200\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     1.0656 Validation Accuracy: 0.572400\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.1610 Validation Accuracy: 0.580600\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     1.0779 Validation Accuracy: 0.590800\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     1.0350 Validation Accuracy: 0.577200\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     1.0260 Validation Accuracy: 0.571800\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     1.0672 Validation Accuracy: 0.576200\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.1961 Validation Accuracy: 0.573600\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     1.0824 Validation Accuracy: 0.583000\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     1.0133 Validation Accuracy: 0.586000\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     1.0371 Validation Accuracy: 0.581000\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     1.0607 Validation Accuracy: 0.571000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.1802 Validation Accuracy: 0.589000\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     1.0877 Validation Accuracy: 0.588200\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     1.0420 Validation Accuracy: 0.589400\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     1.0430 Validation Accuracy: 0.566000\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     1.0648 Validation Accuracy: 0.579600\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.1711 Validation Accuracy: 0.576800\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     1.1030 Validation Accuracy: 0.584000\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     1.0081 Validation Accuracy: 0.592200\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     1.0098 Validation Accuracy: 0.584000\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     1.0555 Validation Accuracy: 0.579800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.1601 Validation Accuracy: 0.586800\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     1.0770 Validation Accuracy: 0.589800\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     1.0274 Validation Accuracy: 0.585000\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     0.9983 Validation Accuracy: 0.587600\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     1.0335 Validation Accuracy: 0.587800\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.1666 Validation Accuracy: 0.582200\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     1.0690 Validation Accuracy: 0.585400\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     1.0051 Validation Accuracy: 0.588200\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     1.0314 Validation Accuracy: 0.593400\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     1.0308 Validation Accuracy: 0.591000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.1709 Validation Accuracy: 0.588000\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     1.0519 Validation Accuracy: 0.590800\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     0.9731 Validation Accuracy: 0.593600\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     1.0014 Validation Accuracy: 0.582000\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     1.0503 Validation Accuracy: 0.592000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.1429 Validation Accuracy: 0.590400\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     1.0355 Validation Accuracy: 0.592800\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     1.0062 Validation Accuracy: 0.592600\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     1.0012 Validation Accuracy: 0.592200\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     1.0005 Validation Accuracy: 0.590400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.1395 Validation Accuracy: 0.588400\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     1.0512 Validation Accuracy: 0.585400\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     0.9878 Validation Accuracy: 0.587800\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     0.9780 Validation Accuracy: 0.591000\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     1.0257 Validation Accuracy: 0.592600\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.1400 Validation Accuracy: 0.593000\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     1.0279 Validation Accuracy: 0.596600\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     0.9987 Validation Accuracy: 0.590200\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     0.9984 Validation Accuracy: 0.585000\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     1.0126 Validation Accuracy: 0.591400\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.1321 Validation Accuracy: 0.592200\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     1.0401 Validation Accuracy: 0.586400\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     0.9964 Validation Accuracy: 0.594800\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     0.9769 Validation Accuracy: 0.601800\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     1.0123 Validation Accuracy: 0.595000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.1083 Validation Accuracy: 0.600600\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     1.0547 Validation Accuracy: 0.600600\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     0.9605 Validation Accuracy: 0.603000\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     0.9861 Validation Accuracy: 0.591200\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     1.0021 Validation Accuracy: 0.594000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.1182 Validation Accuracy: 0.598000\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     1.0246 Validation Accuracy: 0.603000\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     0.9689 Validation Accuracy: 0.598400\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     0.9738 Validation Accuracy: 0.593200\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     0.9828 Validation Accuracy: 0.597000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.1046 Validation Accuracy: 0.599800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     1.0191 Validation Accuracy: 0.587600\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     0.9803 Validation Accuracy: 0.589600\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     0.9647 Validation Accuracy: 0.588800\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     1.0015 Validation Accuracy: 0.594000\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.1132 Validation Accuracy: 0.590400\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     1.0307 Validation Accuracy: 0.606400\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     0.9565 Validation Accuracy: 0.596200\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     0.9602 Validation Accuracy: 0.595400\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     0.9875 Validation Accuracy: 0.599600\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.1210 Validation Accuracy: 0.590600\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     1.0047 Validation Accuracy: 0.601200\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     0.9513 Validation Accuracy: 0.600200\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     0.9578 Validation Accuracy: 0.599600\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     0.9811 Validation Accuracy: 0.601800\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.0997 Validation Accuracy: 0.601400\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     0.9937 Validation Accuracy: 0.604800\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     0.9251 Validation Accuracy: 0.600200\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     0.9521 Validation Accuracy: 0.593400\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     0.9727 Validation Accuracy: 0.602200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.0765 Validation Accuracy: 0.601000\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     0.9981 Validation Accuracy: 0.605600\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     0.9609 Validation Accuracy: 0.597000\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     0.9897 Validation Accuracy: 0.600200\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     0.9764 Validation Accuracy: 0.602200\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.0914 Validation Accuracy: 0.599600\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     0.9957 Validation Accuracy: 0.607000\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     0.9495 Validation Accuracy: 0.601600\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     0.9529 Validation Accuracy: 0.599600\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     0.9872 Validation Accuracy: 0.595200\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.1036 Validation Accuracy: 0.596800\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     1.0194 Validation Accuracy: 0.612000\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     0.9431 Validation Accuracy: 0.610200\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     0.9641 Validation Accuracy: 0.595800\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     0.9633 Validation Accuracy: 0.607800\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.0969 Validation Accuracy: 0.605400\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     1.0017 Validation Accuracy: 0.610600\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     0.9215 Validation Accuracy: 0.611800\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     0.9586 Validation Accuracy: 0.603400\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     0.9859 Validation Accuracy: 0.597400\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.0905 Validation Accuracy: 0.602600\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     0.9591 Validation Accuracy: 0.609800\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     0.9307 Validation Accuracy: 0.608400\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     0.9211 Validation Accuracy: 0.607800\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     0.9706 Validation Accuracy: 0.601800\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.1166 Validation Accuracy: 0.597800\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     0.9811 Validation Accuracy: 0.610400\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     0.9159 Validation Accuracy: 0.608600\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     0.9290 Validation Accuracy: 0.606200\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     0.9682 Validation Accuracy: 0.606600\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.0856 Validation Accuracy: 0.604400\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     0.9771 Validation Accuracy: 0.609400\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     0.9107 Validation Accuracy: 0.607600\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     0.9322 Validation Accuracy: 0.603800\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     0.9671 Validation Accuracy: 0.609400\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.0640 Validation Accuracy: 0.605200\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     0.9751 Validation Accuracy: 0.610000\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     0.9148 Validation Accuracy: 0.606800\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     0.9518 Validation Accuracy: 0.595600\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     0.9797 Validation Accuracy: 0.613800\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.0854 Validation Accuracy: 0.607200\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     0.9634 Validation Accuracy: 0.610800\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     0.9124 Validation Accuracy: 0.606000\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     0.9178 Validation Accuracy: 0.597000\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     0.9509 Validation Accuracy: 0.609200\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.0595 Validation Accuracy: 0.604800\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     0.9648 Validation Accuracy: 0.615400\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     0.9206 Validation Accuracy: 0.610600\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     0.9211 Validation Accuracy: 0.607000\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     0.9597 Validation Accuracy: 0.616600\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.0450 Validation Accuracy: 0.610400\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     0.9725 Validation Accuracy: 0.616200\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     0.9071 Validation Accuracy: 0.610600\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     0.9131 Validation Accuracy: 0.600600\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     0.9432 Validation Accuracy: 0.621000\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.0744 Validation Accuracy: 0.605800\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     0.9529 Validation Accuracy: 0.615800\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     0.8949 Validation Accuracy: 0.611200\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     0.9625 Validation Accuracy: 0.605200\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     0.9367 Validation Accuracy: 0.603400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.0843 Validation Accuracy: 0.609200\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     0.9561 Validation Accuracy: 0.612000\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     0.8799 Validation Accuracy: 0.609400\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     0.9010 Validation Accuracy: 0.606000\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     0.9577 Validation Accuracy: 0.609600\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.0631 Validation Accuracy: 0.611400\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     0.9665 Validation Accuracy: 0.615200\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     0.8854 Validation Accuracy: 0.611000\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     0.9014 Validation Accuracy: 0.609800\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     0.9566 Validation Accuracy: 0.609800\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.0453 Validation Accuracy: 0.611800\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     0.9624 Validation Accuracy: 0.613800\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     0.8996 Validation Accuracy: 0.611000\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     0.9156 Validation Accuracy: 0.615400\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     0.9559 Validation Accuracy: 0.609000\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.0475 Validation Accuracy: 0.610600\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     0.9776 Validation Accuracy: 0.617000\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     0.8859 Validation Accuracy: 0.608600\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     0.9236 Validation Accuracy: 0.613000\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     0.9415 Validation Accuracy: 0.614000\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.0590 Validation Accuracy: 0.607400\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     0.9452 Validation Accuracy: 0.614800\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     0.8974 Validation Accuracy: 0.615200\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     0.9123 Validation Accuracy: 0.611400\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     0.9346 Validation Accuracy: 0.612000\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.0572 Validation Accuracy: 0.615200\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     0.9662 Validation Accuracy: 0.611400\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     0.9089 Validation Accuracy: 0.614200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     0.9216 Validation Accuracy: 0.612800\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     0.9483 Validation Accuracy: 0.605800\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.0535 Validation Accuracy: 0.612600\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     0.9541 Validation Accuracy: 0.621000\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     0.9242 Validation Accuracy: 0.603200\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     0.8823 Validation Accuracy: 0.612000\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     0.9465 Validation Accuracy: 0.611200\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.0619 Validation Accuracy: 0.614000\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     0.9606 Validation Accuracy: 0.610400\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     0.8931 Validation Accuracy: 0.613400\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     0.9007 Validation Accuracy: 0.609600\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     0.9290 Validation Accuracy: 0.612200\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.0394 Validation Accuracy: 0.614200\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     0.9538 Validation Accuracy: 0.614800\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     0.8769 Validation Accuracy: 0.609600\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     0.9047 Validation Accuracy: 0.611800\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     0.9194 Validation Accuracy: 0.615400\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.0409 Validation Accuracy: 0.612600\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     0.9579 Validation Accuracy: 0.614000\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     0.9072 Validation Accuracy: 0.607000\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     0.8953 Validation Accuracy: 0.612400\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     0.9378 Validation Accuracy: 0.616000\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.0263 Validation Accuracy: 0.619800\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     0.9385 Validation Accuracy: 0.618400\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     0.9013 Validation Accuracy: 0.611200\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     0.8968 Validation Accuracy: 0.616600\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     0.9223 Validation Accuracy: 0.618600\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.0398 Validation Accuracy: 0.610800\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     0.9479 Validation Accuracy: 0.616000\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     0.8791 Validation Accuracy: 0.610800\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     0.9130 Validation Accuracy: 0.613800\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     0.9240 Validation Accuracy: 0.615400\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.0146 Validation Accuracy: 0.615400\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     0.9437 Validation Accuracy: 0.618400\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     0.8753 Validation Accuracy: 0.616800\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     0.8745 Validation Accuracy: 0.610800\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     0.9372 Validation Accuracy: 0.609000\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.0368 Validation Accuracy: 0.613000\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     0.9339 Validation Accuracy: 0.620400\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     0.8581 Validation Accuracy: 0.619600\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     0.8782 Validation Accuracy: 0.619200\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     0.9346 Validation Accuracy: 0.612600\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.0543 Validation Accuracy: 0.609600\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     0.9244 Validation Accuracy: 0.620800\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     0.8371 Validation Accuracy: 0.620400\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     0.8840 Validation Accuracy: 0.609600\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     0.8941 Validation Accuracy: 0.614200\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.0120 Validation Accuracy: 0.617000\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     0.9417 Validation Accuracy: 0.613000\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     0.8694 Validation Accuracy: 0.607000\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     0.8896 Validation Accuracy: 0.611400\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     0.9135 Validation Accuracy: 0.617400\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.0269 Validation Accuracy: 0.619600\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     0.9292 Validation Accuracy: 0.618800\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     0.8251 Validation Accuracy: 0.623600\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     0.8827 Validation Accuracy: 0.618600\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     0.9177 Validation Accuracy: 0.621000\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.0143 Validation Accuracy: 0.614600\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     0.9192 Validation Accuracy: 0.626200\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     0.8631 Validation Accuracy: 0.619200\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     0.8690 Validation Accuracy: 0.621800\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     0.9093 Validation Accuracy: 0.618000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.0028 Validation Accuracy: 0.616400\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     0.9256 Validation Accuracy: 0.617000\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     0.8633 Validation Accuracy: 0.613000\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     0.8878 Validation Accuracy: 0.617800\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     0.9236 Validation Accuracy: 0.616400\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     0.9956 Validation Accuracy: 0.618600\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     0.9245 Validation Accuracy: 0.626400\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     0.8328 Validation Accuracy: 0.620400\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     0.8999 Validation Accuracy: 0.613800\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     0.9101 Validation Accuracy: 0.615200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.6109030336141587\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27ebcef8278>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
